## Title: Penetration App -  cyber security  in one base

⬇️ **Download**

```
    git clone https://github.com/Exploit0xfffff/Deep-Actions-Experimental
    cd Deep-Actions-Experimental
    pip install -r requirements.txt
    cd main/
```

Code Description and Future Features :

Project Description:
The "Deep Action Experimental" project is an experimental application that utilizes deep learning techniques for object detection in images and videos. It provides a graphical user interface (GUI) built using the Gtk library in Python.

The main goal of this project is to demonstrate the capabilities of object detection using a pre-trained Faster R-CNN (Region-based Convolutional Neural Network) model. The application allows users to perform object detection on both static images and live video streams.

The application consists of several modules:

1. Home: This module serves as the main entry point of the application and provides an overview of the project.

2. Image Capture: Users can select an image file from their local system and perform object detection on it. The application displays the detected objects along with their corresponding labels and bounding boxes.

3. Live Capture: This module enables users to capture live video streams from a connected camera device and perform real-time object detection. The application continuously processes each frame, detects objects, and overlays the results on the video feed.

4. Video Capture: Users can select a video file from their local system and perform object detection on it. The application processes each frame of the video, detects objects, and generates a new video file with the detected objects highlighted.

The object detection process utilizes a Faster R-CNN model, specifically the "fasterrcnn_resnet50_fpn" model, which is pre-trained on the COCO (Common Objects in Context) dataset. The model is loaded and used for inference on the selected images or video frames. Detected objects are highlighted with bounding boxes and labeled with their corresponding class names.

The application provides a user-friendly interface with a header bar and a menu button for easy navigation between different modules. Users can switch between the Home, Image Capture, Live Capture, and Video Capture modules using the menu options. There is also an option to quit the application.

The "Deep Action Experimental" project serves as a demonstration of the capabilities of deep learning-based object detection and provides a foundation for further exploration and development in the field of computer vision.

Image Capture before ->

![OIP](https://github.com/Exploit0xfffff/Deep-Actions-Experimental/assets/81065703/ae960bdc-79f1-4bd7-8659-ab774d0c8684)


Image Capture after ->

![image](https://github.com/Exploit0xfffff/Deep-Actions-Experimental/assets/81065703/05cdb353-4d81-4b92-93f5-126dd941052c)


Video Capture before ->

https://github.com/Exploit0xfffff/Deep-Actions-Experimental/assets/81065703/d8a39a03-2458-4f28-9099-15a227669734


Video Capture after ->

[output.webm](https://github.com/Exploit0xfffff/Deep-Actions-Experimental/assets/81065703/63106c9b-ec77-4800-8c2b-3cca98f2dada)

- two development stages are there 
- 1) GUI with GTK application should be fix the bugs & create upload button
- 2) the coconames & openai library connection should be on all menu items 

# Ending The Project(DUE TO PLACEMENT HADACHE FINISING PROJECT UPTO HERE WILL BE COMPLETE)

# What-If reopns the project
- 1) create mobile application development process 
- 2) upgrade Home 
- 3) adding google maps & developing 
- 4) upgrade newer versions & libraries 
